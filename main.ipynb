{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relevant values to change are image, lower_bound, upper_bound, erosion_iterations, and connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70 70 70] [316 299 296]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "def change_percent(original :list = [243,230,227] , percent :float = 0.1) -> list:\n",
    "    return [math.ceil(x*(1+percent)) for x in original]\n",
    "# Load the image\n",
    "\n",
    "\n",
    "#### This is the Image Path ####\n",
    "image = cv2.imread('images/petri-dish3.jpeg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for display\n",
    "\n",
    "percent = 0.30 # Change percent for your liking to increase teh precision of the mask\n",
    "##169,155,128\n",
    "# Define the lower and upper bounds for white color in RGB\n",
    "\n",
    "#### Enter the RGB Values of the average blob color here #### ([r,g,b])\n",
    "lower_bound = np.array(change_percent([100,100,100],percent=-percent))\n",
    "upper_bound = np.array(change_percent([243,230,227],percent=percent))\n",
    "\n",
    "print(lower_bound, upper_bound)\n",
    "# Create a mask that identifies the white areas in the image\n",
    "mask = cv2.inRange(image, lower_bound, upper_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true # Skip this Cell\n",
    "\n",
    "\n",
    "# Blur the image for better edge detection\n",
    "img_blur = cv2.GaussianBlur(image,(3,3), sigmaX=0, sigmaY=0)\n",
    "# Convert BGR image to LAB color space\n",
    "lab = cv2.cvtColor(img_blur, cv2.COLOR_BGR2LAB)\n",
    "# Split the LAB image into L, A, and B channels\n",
    "l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "# Enhance contrast in the L channel using histogram equalization\n",
    "l_channel_eq = cv2.equalizeHist(l_channel)\n",
    "# Merge the enhanced L channel with the original A and B channels\n",
    "lab_eq = cv2.merge((l_channel_eq, a_channel, b_channel))\n",
    "\n",
    "# Convert LAB image with enhanced L channel back to BGR\n",
    "contrast = cv2.cvtColor(lab_eq, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "cv2.namedWindow('contrast', cv2.WINDOW_KEEPRATIO)\n",
    "cv2.resizeWindow('contrast', 800, 800)\n",
    "# (Optional) Display the mask and the original image with the blobs highlighted\n",
    "cv2.imshow('contrast', contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true # Skip this Cell\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(image, 50, 150)\n",
    "#edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "cv2.namedWindow('edges', cv2.WINDOW_KEEPRATIO)\n",
    "cv2.resizeWindow('edges', 800, 800)\n",
    "# (Optional) Display the mask and the original image with the blobs highlighted\n",
    "cv2.imshow('edges', edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "# Apply morphological operations to remove noise\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "erosion_iterations = 4 # Play Around with this value. the higher the better. but not too high. depending on image size somewhere between 4 and 7 worked for me but i think between 2 and 8 is feasable\n",
    "dilation_iterations = 0 # keeping this at zero worked best for me\n",
    "\n",
    "# Erode the mask to remove small white noise\n",
    "eroded_mask = cv2.erode(mask, kernel, iterations=erosion_iterations)\n",
    "\n",
    "# Dilate the mask to restore the original size of white areas\n",
    "dilated_mask = cv2.dilate(eroded_mask, kernel, iterations=dilation_iterations)\n",
    "\n",
    "cv2.namedWindow('White Areas Mask', cv2.WINDOW_KEEPRATIO)\n",
    "cv2.resizeWindow('White Areas Mask', 800, 800)\n",
    "# (Optional) Display the mask and the original image with the blobs highlighted\n",
    "cv2.imshow('White Areas Mask', dilated_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of white blobs: 730\n"
     ]
    }
   ],
   "source": [
    "# Find connected components in the mask\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dilated_mask, connectivity=4) # connectivity either 4 or 8 (4 is more precise for our usecase)\n",
    "\n",
    "# Subtract one for the background\n",
    "num_blobs = num_labels - 1\n",
    "\n",
    "window_title = f'Number of white blobs: {num_blobs}'\n",
    "print(window_title)\n",
    "\n",
    "cv2.namedWindow(window_title, cv2.WINDOW_KEEPRATIO)\n",
    "\n",
    "rect_color = (0, 255, 0) # green\n",
    "\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), rect_color , 2)\n",
    "\n",
    "cv2.imshow(window_title, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "cv2.resizeWindow(window_title, 800, 800)\n",
    "cv2.resizeWindow('White Areas Mask', 800, 800)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
